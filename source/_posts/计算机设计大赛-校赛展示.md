---
title: 计算机设计大赛-校赛展示
date: 2018-04-13 16:49:44
tags: [书蕴]
categories: 项目记录
---

# 云朵开场白
BGM响起后，云朵出现
屏幕上巨大的“书蕴”
简单介绍项目

> 书中自有颜如玉，书中自有黄金屋。
> 大家好，我是书蕴的项目负责人陈睿。
> 
> 书蕴，是基于书评内容的书籍推荐系统。
> 希望在信息泛滥的今天，我们能有效地为书籍爱好者提供一片阅读的净土，将阅读带进每个人的心里。
> 
> 话不多说，我们先来看看书蕴本体。
<!-- more -->

# 用户收藏

## 用户画像（词云）
> 首先进入用户界面，每位用户都有自己的收藏夹。系统根据用户收藏书籍的标签集，生成一幅词云。
## 推荐
> 接下来是书蕴最为核心的推荐功能。不同与传统的推荐算法，我们的推荐系统是基于书评的文本内容。我们对书评内容训练出书籍的标签集，根据用户收藏书籍的标签集，在基于大量语料库下训练的标签库中计算标签集之间的距离，将距离最近的书籍推荐给用户。具体思路我会在后续的ppt中详细讲解。
# 搜索
> 搜索是书蕴的另一个特色。根据用户搜索的关键词，计算关键词到标签集的距离进行搜索，将距离最近的书籍呈现给用户。比如搜索科幻，那么出现的则是所有与其相关的书籍。
###书籍详情页面
> 进入书籍三体来看看，这是书籍的详情页面，右上角是这本书籍训练出来得到的标签集的呈现，往下我们可以看到这本书的书评与标签集的匹配效果。
## 绑定豆瓣
> 我们的书籍推荐系统还有很多方便的功能，例如可以通过直接绑定用户的豆瓣id获取用户在豆瓣上收藏的书籍，免去了用户一本本收藏书籍的繁琐操作。

# 引语
那么接下来深入细节，从算法层面讲述我们是如何脱离传统的基于用户的协同过滤算法，从书评文本内容出发，实现智能推荐算法的。
# ppt展示
我们脱离了传统推荐系统的基于用户的协同过滤算法，而是从书评文本内容出发，利用分类方法甄别有效评论、利用文本处理技术建立书籍的标签集、利用深度学习构建标签库，并基于此计算不同书籍的标签集之间的关联度，从而达到基于书评内容推荐书籍的目的。

# 开场白
>首先提两个概念，这两个概念在接下来的陈述中会多次用到。
1.标签集。从系统的角度来看，书籍已经不再是一个对象实体，我们把书籍看作是由许多个关键词组成的标签集，它代表的某一本书。
2.标签库。概念与标签集类似，不同的是标签集是基于某一本书的所有书评；而标签库则是基于我们常用的自然语言构建，它代表的是我们日常使用的语言的全集。
# 目录
>关于去除标签、去停用词、分词等文本预处理的细节这里不予赘述。让我们来看看智能推荐的核心算法。

从整体来看一共有这样四个步骤。接下来我会一一说明。

# 算法

## 筛选关键词
>首先要进行关键词的筛选。这一步主要是去找出书评中真正重要的词。
### TF-IDF
>通过信息检索中词频-逆词频的思想，我们可以计算某一本书籍的书评在所有书评中的TF-IDF值，并排序获取这本书的书评中相对重要的词。换句话说，我们认为这些词是更能够体现这本书的标签。
比如上图的例子，在我们所有书的书评中，三体与红楼梦这两本书的书评中相对重要的关键词如图所示。

## 形成标签集
>找到了相对重要的关键词后，如何形成标签的集合呢？
这里我们并不只是简单的将关键词的整体作为一本书的标签集。因为TF-IDF找到的关键词，往往只在前20个词语上下较为重要，而存在部分重要的词可能无法被找到。所以这里我们额外使用了词向量的解决方案。
### word2vec训练书评模型
>word2vec是自然语言处理中将词语转换为向量表示的技术。我们将每一本书的书评输入到word2vec的三层神经网络中，使用连续词袋法获得每一本书的词向量。
如图所示的是三体这本书所有评论训练得到的词向量。
### word2vec介绍
>为什么要使用词向量呢？
如图使用的是一张word2vec非常有名的训练后的模型。根据词向量，我们可以看到China和Beijing的距离与Russia和Moscow的距离相差不多。
换句话说，中国之于北京，就相当于俄罗斯之于什么？给word2vec提供前三者，我们可以算出是莫斯科。
### word2vec形成标签集
>这里以《追风筝的人》举例，使用这本书的所有书评训练得到的模型如图，当我们输入词语“风筝”，会返回与风筝距离最近的10个词语。返回的结果以余弦值呈现。
据此，我们可以很快想到伪码，以第一步筛选得到的部分关键词加入到标签集实现冷启动，以word2vec去遍历标签集中的词语，取距离最近的前5个词加入到标签集。重复3次这个步骤。
建立的标签集以冷启动+迭代的方式扩展，取距离最近的前5个词决定了标签集的广度，重复3次过程则决定了标签集的深度。
最后是我们得到的标签集
## 建立标签库
>接下来则需要建立标签库，找到标签集之间的关系
###中文维基百科语料库word2vec模型训练
>这是中文维基百科语料库的训练结果，一共训练了80w个词
1.也的确可以通过词向量的完成北京之于中国，正如莫斯科之于俄罗斯 这样的计算。
标签集是每本书的小模型训练得到的结果，而标签库则是使用中文维基百科语料库训练得到的结果。
2.我们再拿前面的图举例子，在追风筝的人这本书里，和风筝距离接近的词语大多和书评相关，而在语料库中，距离接近的词则完全不一样。
因为风筝这个词，在书中的所表达的意义与在平时使用所蕴含的意义大相径庭。
这也是我们标签集训练结果正确性的理论依据。
>标签集只有放在语料库中才能与其他书产生联系，从而找到书与书之间的关联度。
## 计算关联度
>当我们抽取出标签集，构建好标签库之后，剩下的问题就是，如何确定标签集与标签集之间的距离。
>在word2vec模型里，使用词向量可以很快计算得到单个词与单个词之间的距离，我们要解决的是确定多个词与多个词之间的距离
### 关联度计算方法
>我们采用的是分治法模型，首先计算一个词到一个标签集的距离，然后根据标签的重要程度加权平均获得标签集到标签集的距离。
>1在形成标签集到计算关联度之间一共有4个参数，分别决定了筛选关键词、形成标签集与计算关联度的好坏。
2这里的例子使用四本书，分别是三体、三体3、红楼梦与追风筝的人查看效果。期望的结果是三体与三体3的距离十分接近，三体与红楼梦之间的距离十分远。
>这是我们实验过程中保留下来的部分数据，时间关系就不一一细说。经过不断的测试，最后发现冷启动使用前5的关键词，广度为5，深度为3，取标签-书距离取最大值前2时，可以获得最好的结果。
### 关联度计算在推荐系统中的应用
>关联度计算的应用非常多，刚刚具体细说的是我们的核心算法推荐功能。
实际上通过词与标签集的关联度，我们可以实现出模糊搜索的功能。
# thankyou
>最后衷心的感谢各位专家的悉心聆听，
您的提问，是对我们最大的帮助。
